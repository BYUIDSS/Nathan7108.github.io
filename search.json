[
  {
    "objectID": "Competition/project3.html",
    "href": "Competition/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 3"
    ]
  },
  {
    "objectID": "Competition/project4.html",
    "href": "Competition/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 4"
    ]
  },
  {
    "objectID": "Competition/project2.html",
    "href": "Competition/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project5.html",
    "href": "Full_Stack/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 5"
    ]
  },
  {
    "objectID": "Full_Stack/project1.html",
    "href": "Full_Stack/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 1"
    ]
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "Data Exploration",
    "section": "",
    "text": "My work involves analyzing industrial sensor data to understand system behaviors and identify patterns.\n\n\n\nTime-Series Analysis: Examining temporal patterns in sensor readings\nCorrelation Studies: Finding relationships between different sensor types\nAnomaly Detection: Identifying unusual patterns that indicate issues\nPerformance Analysis: Understanding system efficiency and optimization opportunities\n\n\n\n\n\nPython: pandas, numpy, matplotlib for data analysis\nSQL: Extracting and analyzing data from industrial databases\nStatistical Analysis: Understanding data distributions and trends\nData Visualization: Creating charts and dashboards for insights\n\n\n\n\n\nPredictive Maintenance: Using data patterns to predict equipment failures\nPerformance Optimization: Identifying inefficiencies through data analysis\nRisk Assessment: Using historical data to assess potential system failures\n\nThis exploration work helps develop effective AI models and predictive systems for industrial operations.",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "exploration.html#industrial-sensor-data-analysis",
    "href": "exploration.html#industrial-sensor-data-analysis",
    "title": "Data Exploration",
    "section": "",
    "text": "My work involves analyzing industrial sensor data to understand system behaviors and identify patterns.\n\n\n\nTime-Series Analysis: Examining temporal patterns in sensor readings\nCorrelation Studies: Finding relationships between different sensor types\nAnomaly Detection: Identifying unusual patterns that indicate issues\nPerformance Analysis: Understanding system efficiency and optimization opportunities\n\n\n\n\n\nPython: pandas, numpy, matplotlib for data analysis\nSQL: Extracting and analyzing data from industrial databases\nStatistical Analysis: Understanding data distributions and trends\nData Visualization: Creating charts and dashboards for insights\n\n\n\n\n\nPredictive Maintenance: Using data patterns to predict equipment failures\nPerformance Optimization: Identifying inefficiencies through data analysis\nRisk Assessment: Using historical data to assess potential system failures\n\nThis exploration work helps develop effective AI models and predictive systems for industrial operations.",
    "crumbs": [
      "Data Exploration"
    ]
  },
  {
    "objectID": "Machine_Learning/project5.html",
    "href": "Machine_Learning/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 5"
    ]
  },
  {
    "objectID": "Machine_Learning/project1.html",
    "href": "Machine_Learning/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 1"
    ]
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "Full Stack Development",
    "section": "",
    "text": "FastAPI Development: Building high-performance APIs for data processing\nDatabase Design: Designing databases for real-time sensor data\nData Streaming: MQTT-based systems for real-time data transmission\nCaching Strategies: Efficient caching for high-frequency data access\n\n\n\n\n\nMicroservices: Scalable systems using containerized microservices\nAPI Design: FastAPI’s and WebSocket APIs for real-time communication\nDatabase Optimization: Efficient query patterns and indexing\nLoad Balancing: Systems to handle high-volume data streams\n\n\n\n\n\nDocker: Containerizing applications for consistent deployment\nCI/CD: Automating build, test, and deployment processes\nMonitoring: Comprehensive monitoring and logging systems\n\n\n\n\n\nData Visualization: Dashboards and charts for real-time data\nReal-time Updates: WebSocket connections for live data\nResponsive Design: Interfaces for different devices and screens\n\n\n\n\n\nBackend: Python, FastAPI, SQL, Redis, Docker, Kubernetes, MQTT\nFrontend: HTML, CSS, JavaScript, React, Next.js\nDevOps: Docker, Git, CI/CD, monitoring tools\nCommunication: MQTT, Fast APIs, WebSocket\n\n\n\n\n\nIndustrial Data Pipeline: End-to-end systems for data extraction and processing\nReal-time Dashboard: Web interface for monitoring processes\nAPI Gateway: Centralized API management\nData Processing Engine: High-performance data analysis systems\n\n\n\n\n\nQuery Optimization: Reducing query times for large datasets\nCaching: Strategic caching to improve response times\nAuthentication: Secure access controls and data encryption\nError Handling: Robust error recovery and logging\n\nThis experience demonstrates building complete, production-ready systems that bridge industrial hardware with modern software solutions.",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "full_stack.html#industrial-software-development",
    "href": "full_stack.html#industrial-software-development",
    "title": "Full Stack Development",
    "section": "",
    "text": "FastAPI Development: Building high-performance APIs for data processing\nDatabase Design: Designing databases for real-time sensor data\nData Streaming: MQTT-based systems for real-time data transmission\nCaching Strategies: Efficient caching for high-frequency data access\n\n\n\n\n\nMicroservices: Scalable systems using containerized microservices\nAPI Design: FastAPI’s and WebSocket APIs for real-time communication\nDatabase Optimization: Efficient query patterns and indexing\nLoad Balancing: Systems to handle high-volume data streams\n\n\n\n\n\nDocker: Containerizing applications for consistent deployment\nCI/CD: Automating build, test, and deployment processes\nMonitoring: Comprehensive monitoring and logging systems\n\n\n\n\n\nData Visualization: Dashboards and charts for real-time data\nReal-time Updates: WebSocket connections for live data\nResponsive Design: Interfaces for different devices and screens\n\n\n\n\n\nBackend: Python, FastAPI, SQL, Redis, Docker, Kubernetes, MQTT\nFrontend: HTML, CSS, JavaScript, React, Next.js\nDevOps: Docker, Git, CI/CD, monitoring tools\nCommunication: MQTT, Fast APIs, WebSocket\n\n\n\n\n\nIndustrial Data Pipeline: End-to-end systems for data extraction and processing\nReal-time Dashboard: Web interface for monitoring processes\nAPI Gateway: Centralized API management\nData Processing Engine: High-performance data analysis systems\n\n\n\n\n\nQuery Optimization: Reducing query times for large datasets\nCaching: Strategic caching to improve response times\nAuthentication: Secure access controls and data encryption\nError Handling: Robust error recovery and logging\n\nThis experience demonstrates building complete, production-ready systems that bridge industrial hardware with modern software solutions.",
    "crumbs": [
      "Full Stack"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "Machine Learning",
    "section": "",
    "text": "Real-time Processing: AI agents that process industrial sensor data in real-time\nPredictive Modeling: Models to predict equipment failures and maintenance needs\nAnomaly Detection: Systems to identify unusual patterns in industrial data\nAutomated Decisions: AI systems that make operational decisions autonomously\n\n\n\n\n\nPython ML Stack: scikit-learn, TensorFlow, PyTorch for model development\nReal-time Inference: Models that process data streams with minimal latency\nModel Monitoring: Systems to track model performance and drift\nIntegration: Connecting AI models with existing industrial systems\n\n\n\n\n\n\n\n\nObjective: ML model (LSTM/XGBoost) that analyzes historical data to forecast future trends\nApplication: Industrial output, resource demand, or financial metrics forecasting\nFeatures: Dynamic visualizations and real-time predictions for operational decision-making\nTechniques: LSTM, XGBoost, time-series analysis\nTools: Python, LSTM, XGBoost\n\n\n\n\n\nObjective: Comprehensive pipeline that transforms written scripts into short video content\nTechnology: LLMs, image/video APIs, and voice synthesis\nFeatures: Advanced AI coordination across language processing, media generation, and rendering\nTechniques: LLM integration, video generation, voice synthesis\nTools: Python, LLM, Video Generation APIs\n\n\n\n\n\nObjective: Intelligent AI agent that interprets natural language queries and analyzes data sources\nApplication: Uploaded or connected data sources (e.g., CSVs)\nFeatures: Leverages LLM technology to provide accurate, human-readable answers and visual insights\nTechniques: LLM integration, natural language processing, data analysis\nTools: Python, LLM, Data Analysis libraries\n\n\n\n\n\n\nSupervised Learning: Classification, regression, time-series forecasting\nUnsupervised Learning: Clustering, anomaly detection\nDeep Learning: Neural networks, CNNs, RNNs, LSTM\nModel Deployment: Docker containers, API development\nData Engineering: Feature engineering, data preprocessing\n\nThese projects will demonstrate both theoretical understanding and practical application of machine learning.",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "ml.html#current-ai-work",
    "href": "ml.html#current-ai-work",
    "title": "Machine Learning",
    "section": "",
    "text": "Real-time Processing: AI agents that process industrial sensor data in real-time\nPredictive Modeling: Models to predict equipment failures and maintenance needs\nAnomaly Detection: Systems to identify unusual patterns in industrial data\nAutomated Decisions: AI systems that make operational decisions autonomously\n\n\n\n\n\nPython ML Stack: scikit-learn, TensorFlow, PyTorch for model development\nReal-time Inference: Models that process data streams with minimal latency\nModel Monitoring: Systems to track model performance and drift\nIntegration: Connecting AI models with existing industrial systems",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "ml.html#planned-portfolio-projects",
    "href": "ml.html#planned-portfolio-projects",
    "title": "Machine Learning",
    "section": "",
    "text": "Objective: ML model (LSTM/XGBoost) that analyzes historical data to forecast future trends\nApplication: Industrial output, resource demand, or financial metrics forecasting\nFeatures: Dynamic visualizations and real-time predictions for operational decision-making\nTechniques: LSTM, XGBoost, time-series analysis\nTools: Python, LSTM, XGBoost\n\n\n\n\n\nObjective: Comprehensive pipeline that transforms written scripts into short video content\nTechnology: LLMs, image/video APIs, and voice synthesis\nFeatures: Advanced AI coordination across language processing, media generation, and rendering\nTechniques: LLM integration, video generation, voice synthesis\nTools: Python, LLM, Video Generation APIs\n\n\n\n\n\nObjective: Intelligent AI agent that interprets natural language queries and analyzes data sources\nApplication: Uploaded or connected data sources (e.g., CSVs)\nFeatures: Leverages LLM technology to provide accurate, human-readable answers and visual insights\nTechniques: LLM integration, natural language processing, data analysis\nTools: Python, LLM, Data Analysis libraries",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "ml.html#skills",
    "href": "ml.html#skills",
    "title": "Machine Learning",
    "section": "",
    "text": "Supervised Learning: Classification, regression, time-series forecasting\nUnsupervised Learning: Clustering, anomaly detection\nDeep Learning: Neural networks, CNNs, RNNs, LSTM\nModel Deployment: Docker containers, API development\nData Engineering: Feature engineering, data preprocessing\n\nThese projects will demonstrate both theoretical understanding and practical application of machine learning.",
    "crumbs": [
      "Machine Learning"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project3.html",
    "href": "Cleansing_Projects/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 3"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project4.html",
    "href": "Cleansing_Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 4"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project2.html",
    "href": "Cleansing_Projects/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 2"
    ]
  },
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "Story Telling",
    "section": "",
    "text": "My role requires communicating between technical teams and business stakeholders.\n\n\n\nCTO Meetings: Regular discussions about system architecture and technical decisions\nProject Planning: Collaborating with leadership to plan new features\nTechnical Roadmaps: Presenting complex technical plans in business terms\nRisk Assessment: Communicating technical risks and solutions\n\n\n\n\n\nSenior Developer Work: Working with senior developers to debug system issues\nCode Reviews: Participating in technical discussions about code quality\nKnowledge Sharing: Documenting and explaining technical solutions\nProblem-Solving: Facilitating discussions to resolve complex bugs\n\n\n\n\n\nTechnical Documentation: Creating clear documentation for complex systems\nBug Analysis: Translating technical issues into clear problem statements\nSolution Presentations: Explaining technical solutions to different audiences\nProject Updates: Providing regular updates on progress and challenges\n\n\n\n\n\nSystem Issues: Explaining technical problems and recovery plans\nFeature Requests: Translating business needs into technical specifications\nPerformance Problems: Communicating system issues and solutions\nArchitecture Decisions: Explaining technical trade-offs and business impact\n\nEffective communication ensures all stakeholders understand technical challenges and solutions.",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "story_telling.html#bridging-technical-and-business-perspectives",
    "href": "story_telling.html#bridging-technical-and-business-perspectives",
    "title": "Story Telling",
    "section": "",
    "text": "My role requires communicating between technical teams and business stakeholders.\n\n\n\nCTO Meetings: Regular discussions about system architecture and technical decisions\nProject Planning: Collaborating with leadership to plan new features\nTechnical Roadmaps: Presenting complex technical plans in business terms\nRisk Assessment: Communicating technical risks and solutions\n\n\n\n\n\nSenior Developer Work: Working with senior developers to debug system issues\nCode Reviews: Participating in technical discussions about code quality\nKnowledge Sharing: Documenting and explaining technical solutions\nProblem-Solving: Facilitating discussions to resolve complex bugs\n\n\n\n\n\nTechnical Documentation: Creating clear documentation for complex systems\nBug Analysis: Translating technical issues into clear problem statements\nSolution Presentations: Explaining technical solutions to different audiences\nProject Updates: Providing regular updates on progress and challenges\n\n\n\n\n\nSystem Issues: Explaining technical problems and recovery plans\nFeature Requests: Translating business needs into technical specifications\nPerformance Problems: Communicating system issues and solutions\nArchitecture Decisions: Explaining technical trade-offs and business impact\n\nEffective communication ensures all stakeholders understand technical challenges and solutions.",
    "crumbs": [
      "Story Telling"
    ]
  },
  {
    "objectID": "Story_Telling/project5.html",
    "href": "Story_Telling/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 5"
    ]
  },
  {
    "objectID": "Story_Telling/project1.html",
    "href": "Story_Telling/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project3.html",
    "href": "Cleansing_Exploration/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project4.html",
    "href": "Cleansing_Exploration/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project2.html",
    "href": "Cleansing_Exploration/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "Data Cleansing",
    "section": "",
    "text": "During my role at Transpara, I developed a comprehensive data extraction and filtering system for industrial sensor data. While not traditional “data cleansing,” this work involved critical data quality processes:\n\n\n\nData Validation: Implemented validation rules to filter out corrupted sensor readings and invalid data points\nDuplicate Detection: Created algorithms to identify and remove duplicate entries from real-time data streams\nData Quality Assurance: Built automated systems to ensure data integrity before processing by internal calculations\n\n\n\n\n\nReal-time Processing: Handled high-volume industrial data streams with minimal latency\nError Handling: Robust error recovery systems for data pipeline failures\nPerformance Optimization: Efficient filtering algorithms to handle large datasets\nQuality Metrics: Automated reporting on data quality and filtering effectiveness\n\n\n\n\n\nImproved data reliability for data extractors and internal calculations\nReduced false positives in anomaly detection systems\nEnhanced system performance through cleaner data streams\nEstablished data quality standards for industrial applications\n\nThis experience taught me that effective data filtering is often more valuable than traditional “cleansing” in real-time industrial environments where data quality directly impacts operational decisions.",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "cleansing.html#industrial-data-extractor-filtering-system",
    "href": "cleansing.html#industrial-data-extractor-filtering-system",
    "title": "Data Cleansing",
    "section": "",
    "text": "During my role at Transpara, I developed a comprehensive data extraction and filtering system for industrial sensor data. While not traditional “data cleansing,” this work involved critical data quality processes:\n\n\n\nData Validation: Implemented validation rules to filter out corrupted sensor readings and invalid data points\nDuplicate Detection: Created algorithms to identify and remove duplicate entries from real-time data streams\nData Quality Assurance: Built automated systems to ensure data integrity before processing by internal calculations\n\n\n\n\n\nReal-time Processing: Handled high-volume industrial data streams with minimal latency\nError Handling: Robust error recovery systems for data pipeline failures\nPerformance Optimization: Efficient filtering algorithms to handle large datasets\nQuality Metrics: Automated reporting on data quality and filtering effectiveness\n\n\n\n\n\nImproved data reliability for data extractors and internal calculations\nReduced false positives in anomaly detection systems\nEnhanced system performance through cleaner data streams\nEstablished data quality standards for industrial applications\n\nThis experience taught me that effective data filtering is often more valuable than traditional “cleansing” in real-time industrial environments where data quality directly impacts operational decisions.",
    "crumbs": [
      "Data Cleansing"
    ]
  },
  {
    "objectID": "Cleansing_Exploration/project1.html",
    "href": "Cleansing_Exploration/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Cleansing_Exploration/project5.html",
    "href": "Cleansing_Exploration/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top"
  },
  {
    "objectID": "Story_Telling/project2.html",
    "href": "Story_Telling/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 2"
    ]
  },
  {
    "objectID": "Story_Telling/project4.html",
    "href": "Story_Telling/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 4"
    ]
  },
  {
    "objectID": "Story_Telling/project3.html",
    "href": "Story_Telling/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Story Telling",
      "Project 3"
    ]
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Nathan Luckock’s CV",
    "section": "",
    "text": "nathanluckock@gmail.com | My Personal Website"
  },
  {
    "objectID": "resume.html#currently",
    "href": "resume.html#currently",
    "title": "Nathan Luckock’s CV",
    "section": "Currently",
    "text": "Currently\nBuilding backend systems and AI tools that bridge industrial data with real-time intelligence\n\nSpecialized in\nBackend development, FastAPI, Docker, ODBC interfaces, data streaming with MQTT, and not a fan of overcomplicated architectures\n\n\nResearch interests\nReal-time data, API design, caching strategies, AI agents, industrial automation, and making legacy systems actually useful"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Nathan Luckock’s CV",
    "section": "Education",
    "text": "Education\n2024-2026 Brigham Young University Idaho, Rexburg, Idaho.\nBachelor of Science in Computer Science"
  },
  {
    "objectID": "resume.html#awards",
    "href": "resume.html#awards",
    "title": "Nathan Luckock’s CV",
    "section": "Awards",
    "text": "Awards\n2021-2024 National Honors Society"
  },
  {
    "objectID": "resume.html#occupation",
    "href": "resume.html#occupation",
    "title": "Nathan Luckock’s CV",
    "section": "Occupation",
    "text": "Occupation\n2024-present Transpara Software Engineer & Developer, Remote\n\nBuilding backend systems and AI tools that bridge industrial data with real-time intelligence\nDeveloping and maintaining APIs for industrial data streaming and processing\nDesigning and implementing caching strategies for real-time data processing\nDeveloping and maintaining AI agents for real-time data processing\nDeveloping and maintaining industrial automation systems"
  },
  {
    "objectID": "Cleansing_Projects/project1.html",
    "href": "Cleansing_Projects/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 1"
    ]
  },
  {
    "objectID": "Cleansing_Projects/project5.html",
    "href": "Cleansing_Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Data Cleansing",
      "Project 5"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "I build real-world backend systems that connect industrial data to modern platforms. My work spans API development, data streaming, containerized deployment, and cloud integration.\nI’m currently studying Computer Science at BYU–Idaho while working full-time as a software developer. My stack includes FastAPI, Docker, Redis, MQTT, and Kubernetes — and I’ve built scalable services used in production.\n\n\n\n\nDesigned and deployed ODBC interface services using FastAPI\n\nIntegrated MQTT for real-time streaming from industrial systems\n\nBuilt extractors to move crypto and industrial data into modern storage (T-Store)\n\nUsed Docker and Kubernetes for portable, efficient deployments\n\nCreated custom polling and caching layers using Redis\n\n\n\n\nI’m transitioning into data science with plans to build:\n\nPredictive Modeling with Historical Time-Series Data An ML model (LSTM/XGBoost) that analyzes historical data to forecast future trends in industrial output, resource demand, or financial metrics. Features dynamic visualizations and real-time predictions for operational decision-making.\nAI-Powered Script-to-Video Generation Pipeline A comprehensive pipeline that transforms written scripts into short video content using LLMs, image/video APIs, and voice synthesis. Demonstrates advanced AI coordination across language processing, media generation, and rendering tasks.\nNatural Language Agent for Structured Data Analysis An intelligent AI agent that interprets natural language queries and analyzes uploaded or connected data sources (e.g., CSVs). Leverages LLM technology to provide accurate, human-readable answers and visual insights from real business data.\n\n\n\n\nTo combine backend engineering with applied AI and data science — building tools that are both intelligent and production-ready.\n\n\n\nMarkdown Basics"
  },
  {
    "objectID": "index.html#full-time-software-developer-computer-science-student",
    "href": "index.html#full-time-software-developer-computer-science-student",
    "title": "About Me",
    "section": "",
    "text": "I build real-world backend systems that connect industrial data to modern platforms. My work spans API development, data streaming, containerized deployment, and cloud integration.\nI’m currently studying Computer Science at BYU–Idaho while working full-time as a software developer. My stack includes FastAPI, Docker, Redis, MQTT, and Kubernetes — and I’ve built scalable services used in production."
  },
  {
    "objectID": "index.html#what-ive-done",
    "href": "index.html#what-ive-done",
    "title": "About Me",
    "section": "",
    "text": "Designed and deployed ODBC interface services using FastAPI\n\nIntegrated MQTT for real-time streaming from industrial systems\n\nBuilt extractors to move crypto and industrial data into modern storage (T-Store)\n\nUsed Docker and Kubernetes for portable, efficient deployments\n\nCreated custom polling and caching layers using Redis"
  },
  {
    "objectID": "index.html#what-im-exploring",
    "href": "index.html#what-im-exploring",
    "title": "About Me",
    "section": "",
    "text": "I’m transitioning into data science with plans to build:\n\nPredictive Modeling with Historical Time-Series Data An ML model (LSTM/XGBoost) that analyzes historical data to forecast future trends in industrial output, resource demand, or financial metrics. Features dynamic visualizations and real-time predictions for operational decision-making.\nAI-Powered Script-to-Video Generation Pipeline A comprehensive pipeline that transforms written scripts into short video content using LLMs, image/video APIs, and voice synthesis. Demonstrates advanced AI coordination across language processing, media generation, and rendering tasks.\nNatural Language Agent for Structured Data Analysis An intelligent AI agent that interprets natural language queries and analyzes uploaded or connected data sources (e.g., CSVs). Leverages LLM technology to provide accurate, human-readable answers and visual insights from real business data."
  },
  {
    "objectID": "index.html#my-goal",
    "href": "index.html#my-goal",
    "title": "About Me",
    "section": "",
    "text": "To combine backend engineering with applied AI and data science — building tools that are both intelligent and production-ready."
  },
  {
    "objectID": "index.html#more-info",
    "href": "index.html#more-info",
    "title": "About Me",
    "section": "",
    "text": "Markdown Basics"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "Competition",
    "section": "",
    "text": "I have no formal competition experience in data science or machine learning competitions.",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "competition.html#current-status",
    "href": "competition.html#current-status",
    "title": "Competition",
    "section": "",
    "text": "I have no formal competition experience in data science or machine learning competitions.",
    "crumbs": [
      "Competition"
    ]
  },
  {
    "objectID": "Machine_Learning/project2.html",
    "href": "Machine_Learning/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 2"
    ]
  },
  {
    "objectID": "Machine_Learning/project4.html",
    "href": "Machine_Learning/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 4"
    ]
  },
  {
    "objectID": "Machine_Learning/project3.html",
    "href": "Machine_Learning/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Machine Learning",
      "Project 3"
    ]
  },
  {
    "objectID": "Full_Stack/project2.html",
    "href": "Full_Stack/project2.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 2"
    ]
  },
  {
    "objectID": "Full_Stack/project4.html",
    "href": "Full_Stack/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 4"
    ]
  },
  {
    "objectID": "Full_Stack/project3.html",
    "href": "Full_Stack/project3.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Full Stack",
      "Project 3"
    ]
  },
  {
    "objectID": "Competition/project1.html",
    "href": "Competition/project1.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 1"
    ]
  },
  {
    "objectID": "Competition/project5.html",
    "href": "Competition/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "Paste in a template\n\n\n\n\n Back to top",
    "crumbs": [
      "Competition",
      "Project 5"
    ]
  }
]